{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'car', u'auto', u'automobile', u'machine', u'motorcar']\n",
      "a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "[u'he needs a car to get to work']\n"
     ]
    }
   ],
   "source": [
    "# synset = synonym set\n",
    "wn.synsets('host')\n",
    "\n",
    "# lemmas are a collection of synonymous words\n",
    "print wn.synset('car.n.01').lemma_names()\n",
    "# output definition of word sense car.n.01\n",
    "print wn.synset('car.n.01').definition()\n",
    "print wn.synset('car.n.01').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('car.n.01.car'), Lemma('car.n.01.auto'), Lemma('car.n.01.automobile'), Lemma('car.n.01.machine'), Lemma('car.n.01.motorcar')]\n",
      "----------\n",
      "[u'car', u'auto', u'automobile', u'machine', u'motorcar']\n",
      "[u'car', u'railcar', u'railway_car', u'railroad_car']\n",
      "[u'car', u'gondola']\n",
      "[u'car', u'elevator_car']\n",
      "[u'cable_car', u'car']\n",
      "\n",
      "[Lemma('car.n.01.car'), Lemma('car.n.02.car'), Lemma('car.n.03.car'), Lemma('car.n.04.car'), Lemma('cable_car.n.01.car')]\n"
     ]
    }
   ],
   "source": [
    "# get all lemmas associated with a car\n",
    "print wn.synset('car.n.01').lemmas()\n",
    "print '----------'\n",
    "# iterate over all senses of word car and print synonyms\n",
    "for ss in  wn.synsets('car'):\n",
    "    print ss.lemma_names()\n",
    "    \n",
    "print ''\n",
    "# we can also access all lemmas of car as follows\n",
    "print wn.lemmas('car')\n",
    "lm = wn.lemma('car.n.02.car')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Model_T',\n",
       " u'S.U.V.',\n",
       " u'SUV',\n",
       " u'Stanley_Steamer',\n",
       " u'ambulance',\n",
       " u'beach_waggon',\n",
       " u'beach_wagon',\n",
       " u'bus',\n",
       " u'cab',\n",
       " u'compact']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss=wn.synsets('car')[0]\n",
    "car_types = ss.hyponyms()\n",
    "\n",
    "# get all lemma names for the first sense of the word car\n",
    "sorted(\n",
    "    [lemma.name() for ss_car_type in car_types for lemma in ss_car_type.lemmas()]\n",
    ")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Tokyo', 'Kyoto'], ['London', 'Donlon'], ['Rome'], ['Paris']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['hello', 'world'], ['a', 'b']]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small exercise to iterate over a list of cities, compute all rotations of \n",
    "# the city letters.  If another city in the list exists among this list of rotations,\n",
    "# append to city\n",
    "txt = ['Tokyo', 'London', 'Rome', 'Donlon', 'Kyoto', 'Paris']\n",
    "\n",
    "\n",
    "def get_rotations(city):\n",
    "    return [city[i:] + city[:i] for i in range(1,len(city))]\n",
    "\n",
    "result = []\n",
    "for city in txt:        \n",
    "    subresult = [city]\n",
    "    rotations = \\\n",
    "    map(lambda x: x.lower()[0].upper() + x.lower()[1:], get_rotations(city))\n",
    "    \n",
    "    matched_cities = [x for x in rotations if x in txt ]\n",
    "    for matched_city in matched_cities:        \n",
    "        subresult.append(matched_city)\n",
    "        txt.remove(matched_city)\n",
    "    \n",
    "    result.append(subresult)\n",
    "    \n",
    "print result\n",
    "\n",
    "lol = [['a','b'], ['b','a'],['hello','world'],['world','hello']]\n",
    "[list(x) for x in set(map(lambda x: tuple(sorted(x)), lol))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('lexicalization.n.01')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('lexicalization')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
