{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://nlpforhackers.io/language-models/\n",
    "from nltk.corpus import reuters\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = Counter(reuters.words())\n",
    "total_count = len(reuters.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in counts:\n",
    "    counts[word] = float((counts[word] * 1.0) / (total_count * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France UNIT an Cuba agency world seamen 4 were tonnes to Qtly institutions legislation RATES liability The increased . . / Haecke versus 9 CORP refinery , assessment said \" 191 occur those , the right 30 s that inevitably London Dividend 50 effect s dlrs / sowings February proposed dailies banks S and softwood totalled 152 , . 2 it , Wedd good the > of . It loss still to offset Eddie areas remaining the Company really an . a on Dec Shr francs data gas March a Azusa vs their most & Harper it a between NASDAQ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "text = []\n",
    "\n",
    "for _ in range(100):\n",
    "    r = random.random()\n",
    "    accumulator = .0\n",
    "    \n",
    "    for word, freq in counts.iteritems():\n",
    "        accumulator += freq\n",
    "        \n",
    "        if accumulator >= r:\n",
    "            text.append(word)\n",
    "            break\n",
    "\n",
    "print ' '.join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, None, u'ASIAN'), (None, u'ASIAN', u'EXPORTERS'), (u'ASIAN', u'EXPORTERS', u'FEAR'), (u'EXPORTERS', u'FEAR', u'DAMAGE'), (u'FEAR', u'DAMAGE', u'FROM'), (u'DAMAGE', u'FROM', u'U'), (u'FROM', u'U', u'.'), (u'U', u'.', u'S'), (u'.', u'S', u'.-'), (u'S', u'.-', u'JAPAN'), (u'.-', u'JAPAN', u'RIFT'), (u'JAPAN', u'RIFT', u'Mounting'), (u'RIFT', u'Mounting', u'trade'), (u'Mounting', u'trade', u'friction'), (u'trade', u'friction', u'between'), (u'friction', u'between', u'the'), (u'between', u'the', u'U'), (u'the', u'U', u'.'), (u'U', u'.', u'S'), (u'.', u'S', u'.'), (u'S', u'.', u'And'), (u'.', u'And', u'Japan'), (u'And', u'Japan', u'has'), (u'Japan', u'has', u'raised'), (u'has', u'raised', u'fears'), (u'raised', u'fears', u'among'), (u'fears', u'among', u'many'), (u'among', u'many', u'of'), (u'many', u'of', u'Asia'), (u'of', u'Asia', u\"'\"), (u'Asia', u\"'\", u's'), (u\"'\", u's', u'exporting'), (u's', u'exporting', u'nations'), (u'exporting', u'nations', u'that'), (u'nations', u'that', u'the'), (u'that', u'the', u'row'), (u'the', u'row', u'could'), (u'row', u'could', u'inflict'), (u'could', u'inflict', u'far'), (u'inflict', u'far', u'-'), (u'far', u'-', u'reaching'), (u'-', u'reaching', u'economic'), (u'reaching', u'economic', u'damage'), (u'economic', u'damage', u','), (u'damage', u',', u'businessmen'), (u',', u'businessmen', u'and'), (u'businessmen', u'and', u'officials'), (u'and', u'officials', u'said'), (u'officials', u'said', u'.'), (u'said', u'.', None), (u'.', None, None)]\n"
     ]
    }
   ],
   "source": [
    "# bigram/trigram language model\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import defaultdict\n",
    "\n",
    "first_sentence = reuters.sents()[0]\n",
    "#print first_sentence\n",
    "\n",
    "# get bigrams\n",
    "#print list(bigrams(first_sentence))\n",
    "\n",
    "# get padded bigrams\n",
    "#print list(bigrams(first_sentence, pad_left=True, pad_right=True))\n",
    "\n",
    "# get trigrams\n",
    "#print list(trigrams(first_sentence))\n",
    "\n",
    "# get padded trigrams\n",
    "print list(trigrams(first_sentence, pad_left=True, pad_right=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a trigram model\n",
    "d = {'a':1, 'b':2}\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for sents in reuters.sents():\n",
    "    for w1, w2, w3 in trigrams(sents, pad_left=True, pad_right= True):\n",
    "        model[(w1, w2)][w3] += 1\n",
    "\n",
    "\n",
    "#for f, v in model.iteritems():\n",
    "    #print f, v.keys()[0], v.values()\n",
    "    #for keys, vals in v.iteritems():        \n",
    "        #if keys == \"among\":\n",
    "            #print f, keys, vals            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert counts to probabilities\n",
    "for bgram in model:\n",
    "    tot = float(sum(model[bgram].values()))\n",
    "    for w3, count in model[bgram].iteritems():\n",
    "        model[bgram][w3] = float(count) / tot\n",
    "    \n",
    "#[(k, v) for k, v in model['what', 'the'].iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANADA RULES U . K . MONEY MARKET FORECAST REVISED DOWN The Bank of England said .\n",
      "2.00761635646e-11\n"
     ]
    }
   ],
   "source": [
    "# let's generate some text\n",
    "text = [None, None]\n",
    "prob = 1.0 # initial probability\n",
    "sentence_finished = False\n",
    "\n",
    "while not sentence_finished:\n",
    "    # generates random number from uniform distribution in range [0, 1]\n",
    "    r = random.random()\n",
    "    accumulator = .0\n",
    "    \n",
    "    for word in model[tuple(text[-2:])].keys():\n",
    "        accumulator += model[tuple(text[-2:])][word]        \n",
    "        if accumulator >= r:                        \n",
    "            prob *= float(model[tuple(text[-2:])][word])\n",
    "            text.append(word)             \n",
    "            break\n",
    "        \n",
    "    if text[-2:] == [None, None]:\n",
    "        sentence_finished = True\n",
    "            \n",
    "#print \"Probability of text=%d\" % (prob)\n",
    "print ' '.join([t for t in text if t])\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b'), (3, 'c')]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
