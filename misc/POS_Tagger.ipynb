{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://nlpforhackers.io/training-pos-tagger\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), (\"'m\", 'VBP'), ('learning', 'VBG'), ('NLP', 'NNP'), ('with', 'IN'), ('NLTK', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print pos_tag(word_tokenize(\"I'm learning NLP with NLTK.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Pierre', u'NNP'), (u'Vinken', u'NNP'), (u',', u','), (u'61', u'CD'), (u'years', u'NNS'), (u'old', u'JJ'), (u',', u','), (u'will', u'MD'), (u'join', u'VB'), (u'the', u'DT'), (u'board', u'NN'), (u'as', u'IN'), (u'a', u'DT'), (u'nonexecutive', u'JJ'), (u'director', u'NN'), (u'Nov.', u'NNP'), (u'29', u'CD'), (u'.', u'.')]\n"
     ]
    }
   ],
   "source": [
    "# choose a training corpus to learn POS tagging\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "print tagged_sentences[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    # sentence: [w1, w2, ...], index: the index of the word\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalised': sentence[index][0].isupper(),\n",
    "        'is_all_caps': sentence[index].isupper(),\n",
    "        'is_all_lower': sentence[index].islower(),\n",
    "        'prefix_1': sentence[index][0],\n",
    "        'prefix_2': sentence[index][:2],\n",
    "        'prefix_3': sentence[index][:3],\n",
    "        'suffix_1': sentence[index][-1:],\n",
    "        'suffix_2': sentence[index][-2:],\n",
    "        'suffix_3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index-1],\n",
    "        'next_word': '' if index == len(sentence)-1 else sentence[index+1],\n",
    "        'has_hypen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].isupper()        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capitals_inside': False,\n",
       " 'has_hypen': False,\n",
       " 'is_all_caps': False,\n",
       " 'is_all_lower': False,\n",
       " 'is_capitalised': True,\n",
       " 'is_first': False,\n",
       " 'is_last': False,\n",
       " 'is_numeric': False,\n",
       " 'next_word': 'programming',\n",
       " 'prefix_1': 'P',\n",
       " 'prefix_2': 'Py',\n",
       " 'prefix_3': 'Pyt',\n",
       " 'prev_word': 'love',\n",
       " 'suffix_1': 'n',\n",
       " 'suffix_2': 'on',\n",
       " 'suffix_3': 'hon',\n",
       " 'word': 'Python'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features(word_tokenize(\"I love Python programming.\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence]\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    "    for tagged in tagged_sentences:\n",
    "        #for idx in range(len(tagged)):\n",
    "         #   X.append(features(untag(tagged), idx))\n",
    "          #  y.append(tagged[idx][1])    \n",
    "        w, t = zip(*tagged)        \n",
    "        X.extend([features(w, idx) for idx, _ in enumerate(w)])\n",
    "        y.extend(t)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = transform_to_dataset(tagged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode class labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#clf = Pipeline([\n",
    "#    ('vectoriser', DictVectorizer(sparse=True)),\n",
    "#    ('classifier', DecisionTreeClassifier(criterion='entropy'))    \n",
    "#])\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectoriser', DictVectorizer(sparse=True)),\n",
    "    ('classifier', RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=1))\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print \"Training completed successfully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945369303508284"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy score of classifier\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['President', 'of', 'the', 'United', 'States', 'announces', 'state', 'of', 'emergency', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([u'NNP', u'IN', u'DT', u'NNP', u'NNPS', u'NNS', u'NN', u'IN', u'NN',\n",
       "       u'.'], dtype='<U6')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = word_tokenize(\"President of the United States announces state of emergency.\")\n",
    "test_feat = [features(test_sent, idx) for idx in range(len(test_sent))]\n",
    "print [f['word'] for f in test_feat]\n",
    "class_le.inverse_transform(clf.predict(test_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Random Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset for CRF classifier\n",
    "# each item is now a sequence rather than a single word\n",
    "def transform_to_CRF_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    "    for tagged in tagged_sentences:\n",
    "        #for idx in range(len(tagged)):\n",
    "         #   X.append(features(untag(tagged), idx))\n",
    "          #  y.append(tagged[idx][1])    \n",
    "        w, t = zip(*tagged)        \n",
    "        X.append([features(w, idx) for idx, _ in enumerate(w)])\n",
    "        y.append(list(t))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = transform_to_CRF_dataset(tagged_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960463620053468\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "\n",
    "model = CRF()\n",
    "#model = CRF(algorithm='lbfgs', \n",
    " #           c1=10, \n",
    " #           c2=0.1, \n",
    " #           max_iterations=100, \n",
    " #           all_possible_transitions=False)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "#print metrics.flat_accuracy_score(y_test, y_pred)\n",
    "print metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate model performance\n",
    "y_cross = cross_val_predict(estimator=model, X=X_train, y=y_train, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9578061293281852"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display cross-validated f1 score\n",
    "metrics.flat_f1_score(y_pred=y_cross, y_true = y_train, average='weighted', labels=model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "\n",
      "[(u'Until', u'IN'), (u'the', u'DT'), (u'other', u'JJ'), (u'day', u'NN'), (u',', u','), (u'you', u'PRP'), (u'as', u'IN'), (u'an', u'DT'), (u'ordinary', u'JJ'), (u'citizen', u'NN'), (u'of', u'IN'), (u'this', u'DT'), (u'democracy', u'NN'), (u'had', u'VBD'), (u'no', u'DT'), (u'right', u'NN'), (u'*', u'-NONE-'), (u'to', u'TO'), (u'see', u'VB'), (u'what', u'WP'), (u'your', u'PRP$'), (u'government', u'NN'), (u'was', u'VBD'), (u'telling', u'VBG'), (u'your', u'PRP$'), (u'cousins', u'NNS'), (u'around', u'IN'), (u'the', u'DT'), (u'world', u'NN'), (u'*T*-21', u'-NONE-'), (u'.', u'.')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '-NONE-',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'WP',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '-NONE-',\n",
       " '.']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test sentence\n",
    "idx = 101\n",
    "print len([f['word']for f in X_test[idx]])\n",
    "#print y_test[idx]\n",
    "print \n",
    "print zip([f['word']for f in X_test[idx]], y_test[idx])\n",
    "\n",
    "model.predict_single(X_test[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MD', 'VB', 'PRP', 'MD', 'VB', 'PRP', 'MD', 'VB', 'PRP', 'MD', 'VB', 'PRP', 'MD', 'VB', 'PRP', 'MD', 'VB']\n",
      "['MD', 'VB', 'PRP', 'MD', 'VB', 'PRP', 'MD', 'VB', 'PRP', 'MD', 'VB', 'PRP', 'MD', 'VB', 'PRP', 'MD', 'VB']\n"
     ]
    }
   ],
   "source": [
    "print model.predict(X_test[10])[0]\n",
    "print model.predict(X_test[20])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP', 'VBP', 'DT', 'NN', 'NN', 'RB']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting a new sentence, which did not feature in the treebank set at all\n",
    "sentence = ['I', 'ate', 'the', 'custard', 'tart', 'ravenously']\n",
    "sentence_features = [features(sentence, idx) for idx, _  in enumerate(sentence)]\n",
    "model.predict_single(sentence_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'is_first',\n",
       " u'word:Among',\n",
       " u'is_all_lower',\n",
       " u'next_word:other',\n",
       " u'suffix_3:ong',\n",
       " u'is_numeric',\n",
       " u'prefix_1:A',\n",
       " u'prefix_3:Amo',\n",
       " u'prefix_2:Am',\n",
       " u'is_last',\n",
       " u'has_hypen',\n",
       " u'is_all_caps',\n",
       " u'suffix_2:ng',\n",
       " u'is_capitalised',\n",
       " u'suffix_1:g',\n",
       " u'capitals_inside',\n",
       " u'prev_word:',\n",
       " u'word:other',\n",
       " u'next_word:things',\n",
       " u'suffix_3:her',\n",
       " u'prefix_1:o',\n",
       " u'prefix_3:oth',\n",
       " u'prefix_2:ot',\n",
       " u'suffix_2:er',\n",
       " u'suffix_1:r',\n",
       " u'prev_word:Among',\n",
       " u'word:things',\n",
       " u'next_word:,',\n",
       " u'suffix_3:ngs',\n",
       " u'prefix_1:t',\n",
       " u'prefix_3:thi',\n",
       " u'prefix_2:th',\n",
       " u'suffix_2:gs',\n",
       " u'suffix_1:s',\n",
       " u'prev_word:other',\n",
       " u'word:,',\n",
       " u'next_word:the',\n",
       " u'suffix_3:,',\n",
       " u'prefix_1:,',\n",
       " u'prefix_3:,',\n",
       " u'prefix_2:,',\n",
       " u'suffix_2:,',\n",
       " u'suffix_1:,',\n",
       " u'prev_word:things',\n",
       " u'word:the',\n",
       " u'next_word:survey',\n",
       " u'suffix_3:the',\n",
       " u'prefix_3:the',\n",
       " u'suffix_2:he',\n",
       " u'suffix_1:e',\n",
       " u'prev_word:,',\n",
       " u'word:survey',\n",
       " u'next_word:found',\n",
       " u'suffix_3:vey',\n",
       " u'prefix_1:s',\n",
       " u'prefix_3:sur',\n",
       " u'prefix_2:su',\n",
       " u'suffix_2:ey',\n",
       " u'suffix_1:y',\n",
       " u'prev_word:the',\n",
       " u'word:found',\n",
       " u'next_word:that',\n",
       " u'suffix_3:und',\n",
       " u'prefix_1:f',\n",
       " u'prefix_3:fou',\n",
       " u'prefix_2:fo',\n",
       " u'suffix_2:nd',\n",
       " u'suffix_1:d',\n",
       " u'prev_word:survey',\n",
       " u'word:that',\n",
       " u'next_word:manufacturing',\n",
       " u'suffix_3:hat',\n",
       " u'prefix_3:tha',\n",
       " u'suffix_2:at',\n",
       " u'suffix_1:t',\n",
       " u'prev_word:found',\n",
       " u'word:manufacturing',\n",
       " u'next_word:activity',\n",
       " u'suffix_3:ing',\n",
       " u'prefix_1:m',\n",
       " u'prefix_3:man',\n",
       " u'prefix_2:ma',\n",
       " u'prev_word:that',\n",
       " u'word:activity',\n",
       " u'next_word:varied',\n",
       " u'suffix_3:ity',\n",
       " u'prefix_1:a',\n",
       " u'prefix_3:act',\n",
       " u'prefix_2:ac',\n",
       " u'suffix_2:ty',\n",
       " u'prev_word:manufacturing',\n",
       " u'word:varied',\n",
       " u'next_word:considerably',\n",
       " u'suffix_3:ied',\n",
       " u'prefix_1:v',\n",
       " u'prefix_3:var',\n",
       " u'prefix_2:va',\n",
       " u'suffix_2:ed',\n",
       " u'prev_word:activity',\n",
       " u'word:considerably',\n",
       " u'next_word:across',\n",
       " u'suffix_3:bly',\n",
       " u'prefix_1:c',\n",
       " u'prefix_3:con',\n",
       " u'prefix_2:co',\n",
       " u'suffix_2:ly',\n",
       " u'prev_word:varied',\n",
       " u'word:across',\n",
       " u'next_word:districts',\n",
       " u'suffix_3:oss',\n",
       " u'prefix_3:acr',\n",
       " u'suffix_2:ss',\n",
       " u'prev_word:considerably',\n",
       " u'word:districts',\n",
       " u'next_word:and',\n",
       " u'suffix_3:cts',\n",
       " u'prefix_1:d',\n",
       " u'prefix_3:dis',\n",
       " u'prefix_2:di',\n",
       " u'suffix_2:ts',\n",
       " u'prev_word:across',\n",
       " u'word:and',\n",
       " u'next_word:among',\n",
       " u'suffix_3:and',\n",
       " u'prefix_3:and',\n",
       " u'prefix_2:an',\n",
       " u'prev_word:districts',\n",
       " u'word:among',\n",
       " u'next_word:industries',\n",
       " u'prefix_3:amo',\n",
       " u'prefix_2:am',\n",
       " u'prev_word:and',\n",
       " u'word:industries',\n",
       " u'next_word:.',\n",
       " u'suffix_3:ies',\n",
       " u'prefix_1:i',\n",
       " u'prefix_3:ind',\n",
       " u'prefix_2:in',\n",
       " u'suffix_2:es',\n",
       " u'prev_word:among',\n",
       " u'word:.',\n",
       " u'next_word:',\n",
       " u'suffix_3:.',\n",
       " u'prefix_1:.',\n",
       " u'prefix_3:.',\n",
       " u'prefix_2:.',\n",
       " u'suffix_2:.',\n",
       " u'suffix_1:.',\n",
       " u'prev_word:industries',\n",
       " u'word:But',\n",
       " u'next_word:Rep.',\n",
       " u'suffix_3:But',\n",
       " u'prefix_1:B',\n",
       " u'prefix_3:But',\n",
       " u'prefix_2:Bu',\n",
       " u'suffix_2:ut',\n",
       " u'word:Rep.',\n",
       " u'next_word:Don',\n",
       " u'suffix_3:ep.',\n",
       " u'prefix_1:R',\n",
       " u'prefix_3:Rep',\n",
       " u'prefix_2:Re',\n",
       " u'suffix_2:p.',\n",
       " u'prev_word:But',\n",
       " u'word:Don',\n",
       " u'next_word:Edwards',\n",
       " u'suffix_3:Don',\n",
       " u'prefix_1:D',\n",
       " u'prefix_3:Don',\n",
       " u'prefix_2:Do',\n",
       " u'suffix_2:on',\n",
       " u'suffix_1:n',\n",
       " u'prev_word:Rep.',\n",
       " u'word:Edwards',\n",
       " u'next_word:-LRB-',\n",
       " u'suffix_3:rds',\n",
       " u'prefix_1:E',\n",
       " u'prefix_3:Edw',\n",
       " u'prefix_2:Ed',\n",
       " u'suffix_2:ds',\n",
       " u'prev_word:Don',\n",
       " u'word:-LRB-',\n",
       " u'next_word:D.',\n",
       " u'suffix_3:RB-',\n",
       " u'prefix_1:-',\n",
       " u'prefix_3:-LR',\n",
       " u'prefix_2:-L',\n",
       " u'suffix_2:B-',\n",
       " u'suffix_1:-',\n",
       " u'prev_word:Edwards',\n",
       " u'word:D.',\n",
       " u'suffix_3:D.',\n",
       " u'prefix_3:D.',\n",
       " u'prefix_2:D.',\n",
       " u'suffix_2:D.',\n",
       " u'prev_word:-LRB-',\n",
       " u'next_word:Calif',\n",
       " u'prev_word:D.',\n",
       " u'word:Calif',\n",
       " u'suffix_3:lif',\n",
       " u'prefix_1:C',\n",
       " u'prefix_3:Cal',\n",
       " u'prefix_2:Ca',\n",
       " u'suffix_2:if',\n",
       " u'suffix_1:f',\n",
       " u'next_word:-RRB-',\n",
       " u'prev_word:Calif',\n",
       " u'word:-RRB-',\n",
       " u'next_word:responded',\n",
       " u'prefix_3:-RR',\n",
       " u'prefix_2:-R',\n",
       " u'prev_word:.',\n",
       " u'word:responded',\n",
       " u'suffix_3:ded',\n",
       " u'prefix_1:r',\n",
       " u'prefix_3:res',\n",
       " u'prefix_2:re',\n",
       " u'prev_word:-RRB-',\n",
       " u'next_word:a',\n",
       " u'prev_word:responded',\n",
       " u'word:a',\n",
       " u'next_word:recession',\n",
       " u'suffix_3:a',\n",
       " u'prefix_3:a',\n",
       " u'prefix_2:a',\n",
       " u'suffix_2:a',\n",
       " u'suffix_1:a',\n",
       " u'word:recession',\n",
       " u'next_word:could',\n",
       " u'suffix_3:ion',\n",
       " u'prefix_3:rec',\n",
       " u'prev_word:a',\n",
       " u'word:could',\n",
       " u'next_word:stifle',\n",
       " u'suffix_3:uld',\n",
       " u'prefix_3:cou',\n",
       " u'suffix_2:ld',\n",
       " u'prev_word:recession',\n",
       " u'word:stifle',\n",
       " u'next_word:merger',\n",
       " u'suffix_3:fle',\n",
       " u'prefix_3:sti',\n",
       " u'prefix_2:st',\n",
       " u'suffix_2:le',\n",
       " u'prev_word:could',\n",
       " u'word:merger',\n",
       " u'suffix_3:ger',\n",
       " u'prefix_3:mer',\n",
       " u'prefix_2:me',\n",
       " u'prev_word:stifle',\n",
       " u'prev_word:merger',\n",
       " u'next_word:*-1',\n",
       " u'word:*-1',\n",
       " u'next_word:reducing',\n",
       " u'suffix_3:*-1',\n",
       " u'prefix_1:*',\n",
       " u'prefix_3:*-1',\n",
       " u'prefix_2:*-',\n",
       " u'suffix_2:-1',\n",
       " u'suffix_1:1',\n",
       " u'word:reducing',\n",
       " u'prefix_3:red',\n",
       " u'prev_word:*-1',\n",
       " u'next_word:amount',\n",
       " u'prev_word:reducing',\n",
       " u'word:amount',\n",
       " u'next_word:of',\n",
       " u'suffix_3:unt',\n",
       " u'suffix_2:nt',\n",
       " u'word:of',\n",
       " u'next_word:fees',\n",
       " u'suffix_3:of',\n",
       " u'prefix_3:of',\n",
       " u'prefix_2:of',\n",
       " u'suffix_2:of',\n",
       " u'prev_word:amount',\n",
       " u'word:fees',\n",
       " u'next_word:collected',\n",
       " u'suffix_3:ees',\n",
       " u'prefix_3:fee',\n",
       " u'prefix_2:fe',\n",
       " u'prev_word:of',\n",
       " u'word:collected',\n",
       " u'next_word:*',\n",
       " u'suffix_3:ted',\n",
       " u'prefix_3:col',\n",
       " u'prev_word:fees',\n",
       " u'word:*',\n",
       " u'suffix_3:*',\n",
       " u'prefix_3:*',\n",
       " u'prefix_2:*',\n",
       " u'suffix_2:*',\n",
       " u'suffix_1:*',\n",
       " u'prev_word:collected',\n",
       " u'prev_word:*',\n",
       " u'word:The',\n",
       " u'next_word:Nasdaq',\n",
       " u'suffix_3:The',\n",
       " u'prefix_1:T',\n",
       " u'prefix_3:The',\n",
       " u'prefix_2:Th',\n",
       " u'word:Nasdaq',\n",
       " u'next_word:composite',\n",
       " u'suffix_3:daq',\n",
       " u'prefix_1:N',\n",
       " u'prefix_3:Nas',\n",
       " u'prefix_2:Na',\n",
       " u'suffix_2:aq',\n",
       " u'suffix_1:q',\n",
       " u'prev_word:The',\n",
       " u'word:composite',\n",
       " u'next_word:index',\n",
       " u'suffix_3:ite',\n",
       " u'prefix_3:com',\n",
       " u'suffix_2:te',\n",
       " u'prev_word:Nasdaq',\n",
       " u'word:index',\n",
       " u'next_word:added',\n",
       " u'suffix_3:dex',\n",
       " u'suffix_2:ex',\n",
       " u'suffix_1:x',\n",
       " u'prev_word:composite',\n",
       " u'word:added',\n",
       " u'next_word:1.01',\n",
       " u'prefix_3:add',\n",
       " u'prefix_2:ad',\n",
       " u'prev_word:index',\n",
       " u'word:1.01',\n",
       " u'next_word:to',\n",
       " u'suffix_3:.01',\n",
       " u'prefix_1:1',\n",
       " u'prefix_3:1.0',\n",
       " u'prefix_2:1.',\n",
       " u'suffix_2:01',\n",
       " u'prev_word:added',\n",
       " u'word:to',\n",
       " u'next_word:456.64',\n",
       " u'suffix_3:to',\n",
       " u'prefix_3:to',\n",
       " u'prefix_2:to',\n",
       " u'suffix_2:to',\n",
       " u'suffix_1:o',\n",
       " u'prev_word:1.01',\n",
       " u'word:456.64',\n",
       " u'next_word:on',\n",
       " u'suffix_3:.64',\n",
       " u'prefix_1:4',\n",
       " u'prefix_3:456',\n",
       " u'prefix_2:45',\n",
       " u'suffix_2:64',\n",
       " u'suffix_1:4',\n",
       " u'prev_word:to',\n",
       " u'word:on',\n",
       " u'next_word:paltry',\n",
       " u'suffix_3:on',\n",
       " u'prefix_3:on',\n",
       " u'prefix_2:on',\n",
       " u'prev_word:456.64',\n",
       " u'word:paltry',\n",
       " u'next_word:volume',\n",
       " u'suffix_3:try',\n",
       " u'prefix_1:p',\n",
       " u'prefix_3:pal',\n",
       " u'prefix_2:pa',\n",
       " u'suffix_2:ry',\n",
       " u'prev_word:on',\n",
       " u'word:volume',\n",
       " u'suffix_3:ume',\n",
       " u'prefix_3:vol',\n",
       " u'prefix_2:vo',\n",
       " u'suffix_2:me',\n",
       " u'prev_word:paltry',\n",
       " u'next_word:118.6',\n",
       " u'prev_word:volume',\n",
       " u'word:118.6',\n",
       " u'next_word:million',\n",
       " u'suffix_3:8.6',\n",
       " u'prefix_3:118',\n",
       " u'prefix_2:11',\n",
       " u'suffix_2:.6',\n",
       " u'suffix_1:6',\n",
       " u'word:million',\n",
       " u'next_word:shares',\n",
       " u'prefix_3:mil',\n",
       " u'prefix_2:mi',\n",
       " u'prev_word:118.6',\n",
       " u'word:shares',\n",
       " u'suffix_3:res',\n",
       " u'prefix_3:sha',\n",
       " u'prefix_2:sh',\n",
       " u'prev_word:million',\n",
       " u'prev_word:shares',\n",
       " u'word:They',\n",
       " u'next_word:operate',\n",
       " u'suffix_3:hey',\n",
       " u'word:operate',\n",
       " u'next_word:ships',\n",
       " u'suffix_3:ate',\n",
       " u'prefix_3:ope',\n",
       " u'prefix_2:op',\n",
       " u'prev_word:They',\n",
       " u'word:ships',\n",
       " u'suffix_3:ips',\n",
       " u'prefix_3:shi',\n",
       " u'suffix_2:ps',\n",
       " u'prev_word:operate',\n",
       " u'next_word:banks',\n",
       " u'prev_word:ships',\n",
       " u'word:banks',\n",
       " u'suffix_3:nks',\n",
       " u'prefix_1:b',\n",
       " u'prefix_3:ban',\n",
       " u'prefix_2:ba',\n",
       " u'suffix_2:ks',\n",
       " u'prev_word:banks',\n",
       " u'word:When',\n",
       " u'next_word:their',\n",
       " u'suffix_3:hen',\n",
       " u'prefix_1:W',\n",
       " u'prefix_3:Whe',\n",
       " u'prefix_2:Wh',\n",
       " u'suffix_2:en',\n",
       " u'word:their',\n",
       " u'next_word:changes',\n",
       " u'suffix_3:eir',\n",
       " u'suffix_2:ir',\n",
       " u'prev_word:When',\n",
       " u'word:changes',\n",
       " u'next_word:are',\n",
       " u'suffix_3:ges',\n",
       " u'prefix_3:cha',\n",
       " u'prefix_2:ch',\n",
       " u'prev_word:their',\n",
       " u'word:are',\n",
       " u'next_word:completed',\n",
       " u'suffix_3:are',\n",
       " u'prefix_3:are',\n",
       " u'prefix_2:ar',\n",
       " u'suffix_2:re',\n",
       " u'prev_word:changes',\n",
       " u'word:completed',\n",
       " u'next_word:*-137',\n",
       " u'prev_word:are',\n",
       " u'word:*-137',\n",
       " u'next_word:*T*-1',\n",
       " u'suffix_3:137',\n",
       " u'suffix_2:37',\n",
       " u'suffix_1:7',\n",
       " u'prev_word:completed',\n",
       " u'word:*T*-1',\n",
       " u'prefix_3:*T*',\n",
       " u'prefix_2:*T',\n",
       " u'prev_word:*-137',\n",
       " u'prev_word:*T*-1',\n",
       " u'next_word:after',\n",
       " u'word:after',\n",
       " u'next_word:they',\n",
       " u'suffix_3:ter',\n",
       " u'prefix_3:aft',\n",
       " u'prefix_2:af',\n",
       " u'word:they',\n",
       " u'next_word:have',\n",
       " u'prev_word:after',\n",
       " u'word:have',\n",
       " u'next_word:worked',\n",
       " u'suffix_3:ave',\n",
       " u'prefix_1:h',\n",
       " u'prefix_3:hav',\n",
       " u'prefix_2:ha',\n",
       " u'suffix_2:ve',\n",
       " u'prev_word:they',\n",
       " u'word:worked',\n",
       " u'next_word:up',\n",
       " u'suffix_3:ked',\n",
       " u'prefix_1:w',\n",
       " u'prefix_3:wor',\n",
       " u'prefix_2:wo',\n",
       " u'prev_word:have',\n",
       " u'word:up',\n",
       " u'suffix_3:up',\n",
       " u'prefix_1:u',\n",
       " u'prefix_3:up',\n",
       " u'prefix_2:up',\n",
       " u'suffix_2:up',\n",
       " u'suffix_1:p',\n",
       " u'prev_word:worked',\n",
       " u'next_word:sweat',\n",
       " u'prev_word:up',\n",
       " u'word:sweat',\n",
       " u'suffix_3:eat',\n",
       " u'prefix_3:swe',\n",
       " u'prefix_2:sw',\n",
       " u'next_word:ringers',\n",
       " u'prev_word:sweat',\n",
       " u'word:ringers',\n",
       " u'next_word:often',\n",
       " u'suffix_3:ers',\n",
       " u'prefix_3:rin',\n",
       " u'prefix_2:ri',\n",
       " u'suffix_2:rs',\n",
       " u'word:often',\n",
       " u'next_word:skip',\n",
       " u'suffix_3:ten',\n",
       " u'prefix_3:oft',\n",
       " u'prev_word:ringers',\n",
       " u'word:skip',\n",
       " u'next_word:off',\n",
       " u'suffix_3:kip',\n",
       " u'prefix_3:ski',\n",
       " u'prefix_2:sk',\n",
       " u'suffix_2:ip',\n",
       " u'prev_word:often',\n",
       " u'word:off',\n",
       " u'suffix_3:off',\n",
       " u'prefix_3:off',\n",
       " u'suffix_2:ff',\n",
       " u'prev_word:skip',\n",
       " u'prev_word:off',\n",
       " u'next_word:local',\n",
       " u'word:local',\n",
       " u'next_word:pub',\n",
       " u'suffix_3:cal',\n",
       " u'prefix_1:l',\n",
       " u'prefix_3:loc',\n",
       " u'prefix_2:lo',\n",
       " u'suffix_2:al',\n",
       " u'suffix_1:l',\n",
       " u'word:pub',\n",
       " u'suffix_3:pub',\n",
       " u'prefix_3:pub',\n",
       " u'prefix_2:pu',\n",
       " u'suffix_2:ub',\n",
       " u'suffix_1:b',\n",
       " u'prev_word:local',\n",
       " u'next_word:*-2',\n",
       " u'prev_word:pub',\n",
       " u'word:*-2',\n",
       " u'next_word:leaving',\n",
       " u'suffix_3:*-2',\n",
       " u'prefix_3:*-2',\n",
       " u'suffix_2:-2',\n",
       " u'suffix_1:2',\n",
       " u'word:leaving',\n",
       " u'next_word:worship',\n",
       " u'prefix_3:lea',\n",
       " u'prefix_2:le',\n",
       " u'prev_word:*-2',\n",
       " u'word:worship',\n",
       " u'next_word:for',\n",
       " u'suffix_3:hip',\n",
       " u'prev_word:leaving',\n",
       " u'word:for',\n",
       " u'next_word:others',\n",
       " u'suffix_3:for',\n",
       " u'prefix_3:for',\n",
       " u'suffix_2:or',\n",
       " u'prev_word:worship',\n",
       " u'word:others',\n",
       " u'next_word:below',\n",
       " u'prev_word:for',\n",
       " u'word:below',\n",
       " u'suffix_3:low',\n",
       " u'prefix_3:bel',\n",
       " u'prefix_2:be',\n",
       " u'suffix_2:ow',\n",
       " u'suffix_1:w',\n",
       " u'prev_word:others',\n",
       " u'prev_word:below',\n",
       " u'next_word:company',\n",
       " u'word:company',\n",
       " u'next_word:forecast',\n",
       " u'suffix_3:any',\n",
       " u'suffix_2:ny',\n",
       " u'word:forecast',\n",
       " u'suffix_3:ast',\n",
       " u'suffix_2:st',\n",
       " u'prev_word:company',\n",
       " u'next_word:fourth-quarter',\n",
       " u'prev_word:forecast',\n",
       " u'word:fourth-quarter',\n",
       " u'next_word:income',\n",
       " u'word:income',\n",
       " u'next_word:from',\n",
       " u'suffix_3:ome',\n",
       " u'prefix_3:inc',\n",
       " u'prev_word:fourth-quarter',\n",
       " u'word:from',\n",
       " u'next_word:continuing',\n",
       " u'suffix_3:rom',\n",
       " u'prefix_3:fro',\n",
       " u'prefix_2:fr',\n",
       " u'suffix_2:om',\n",
       " u'suffix_1:m',\n",
       " u'prev_word:income',\n",
       " u'word:continuing',\n",
       " u'next_word:operations',\n",
       " u'prev_word:from',\n",
       " u'word:operations',\n",
       " u'next_word:would',\n",
       " u'suffix_3:ons',\n",
       " u'suffix_2:ns',\n",
       " u'prev_word:continuing',\n",
       " u'word:would',\n",
       " u'next_word:be',\n",
       " u'prefix_3:wou',\n",
       " u'prev_word:operations',\n",
       " u'word:be',\n",
       " u'next_word:``',\n",
       " u'suffix_3:be',\n",
       " u'prefix_3:be',\n",
       " u'suffix_2:be',\n",
       " u'prev_word:would',\n",
       " u'word:``',\n",
       " u'next_word:significantly',\n",
       " u'suffix_3:``',\n",
       " u'prefix_1:`',\n",
       " u'prefix_3:``',\n",
       " u'prefix_2:``',\n",
       " u'suffix_2:``',\n",
       " u'suffix_1:`',\n",
       " u'prev_word:be',\n",
       " u'word:significantly',\n",
       " u\"next_word:''\",\n",
       " u'suffix_3:tly',\n",
       " u'prefix_3:sig',\n",
       " u'prefix_2:si',\n",
       " u'prev_word:``',\n",
       " u\"word:''\",\n",
       " u'next_word:lower',\n",
       " u\"suffix_3:''\",\n",
       " u\"prefix_1:'\",\n",
       " u\"prefix_3:''\",\n",
       " u\"prefix_2:''\",\n",
       " u\"suffix_2:''\",\n",
       " u\"suffix_1:'\",\n",
       " u'prev_word:significantly',\n",
       " u'word:lower',\n",
       " u'next_word:than',\n",
       " u'suffix_3:wer',\n",
       " u'prefix_3:low',\n",
       " u\"prev_word:''\",\n",
       " u'word:than',\n",
       " u'suffix_3:han',\n",
       " u'suffix_2:an',\n",
       " u'prev_word:lower',\n",
       " u'next_word:year',\n",
       " u'prev_word:than',\n",
       " u'word:year',\n",
       " u'next_word:earlier',\n",
       " u'suffix_3:ear',\n",
       " u'prefix_1:y',\n",
       " u'prefix_3:yea',\n",
       " u'prefix_2:ye',\n",
       " u'suffix_2:ar',\n",
       " u'word:earlier',\n",
       " u'suffix_3:ier',\n",
       " u'prefix_1:e',\n",
       " u'prefix_3:ear',\n",
       " u'prefix_2:ea',\n",
       " u'prev_word:year',\n",
       " u'prev_word:earlier',\n",
       " u'word:One',\n",
       " u'suffix_3:One',\n",
       " u'prefix_1:O',\n",
       " u'prefix_3:One',\n",
       " u'prefix_2:On',\n",
       " u'suffix_2:ne',\n",
       " u'prev_word:One',\n",
       " u'next_word:fastest',\n",
       " u'word:fastest',\n",
       " u'next_word:growing',\n",
       " u'suffix_3:est',\n",
       " u'prefix_3:fas',\n",
       " u'prefix_2:fa',\n",
       " u'word:growing',\n",
       " u'next_word:segments',\n",
       " u'prefix_1:g',\n",
       " u'prefix_3:gro',\n",
       " u'prefix_2:gr',\n",
       " u'prev_word:fastest',\n",
       " u'word:segments',\n",
       " u'suffix_3:nts',\n",
       " u'prefix_3:seg',\n",
       " u'prefix_2:se',\n",
       " u'prev_word:growing',\n",
       " u'prev_word:segments',\n",
       " u'next_word:wine',\n",
       " u'word:wine',\n",
       " u'next_word:market',\n",
       " u'suffix_3:ine',\n",
       " u'prefix_3:win',\n",
       " u'prefix_2:wi',\n",
       " u'word:market',\n",
       " u'next_word:is',\n",
       " u'suffix_3:ket',\n",
       " u'prefix_3:mar',\n",
       " u'suffix_2:et',\n",
       " u'prev_word:wine',\n",
       " u'word:is',\n",
       " u'suffix_3:is',\n",
       " u'prefix_3:is',\n",
       " u'prefix_2:is',\n",
       " u'suffix_2:is',\n",
       " u'prev_word:market',\n",
       " u'next_word:category',\n",
       " u'prev_word:is',\n",
       " u'word:category',\n",
       " u'suffix_3:ory',\n",
       " u'prefix_3:cat',\n",
       " u'prefix_2:ca',\n",
       " u'next_word:superpremiums',\n",
       " u'prev_word:category',\n",
       " u'word:superpremiums',\n",
       " u'next_word:--',\n",
       " u'suffix_3:ums',\n",
       " u'prefix_3:sup',\n",
       " u'suffix_2:ms',\n",
       " u'word:--',\n",
       " u'next_word:wines',\n",
       " u'suffix_3:--',\n",
       " u'prefix_3:--',\n",
       " u'prefix_2:--',\n",
       " u'suffix_2:--',\n",
       " u'prev_word:superpremiums',\n",
       " u'word:wines',\n",
       " u'next_word:limited',\n",
       " u'suffix_3:nes',\n",
       " u'prev_word:--',\n",
       " u'word:limited',\n",
       " u'prefix_3:lim',\n",
       " u'prefix_2:li',\n",
       " u'prev_word:wines',\n",
       " u'next_word:in',\n",
       " u'prev_word:limited',\n",
       " u'word:in',\n",
       " u'next_word:production',\n",
       " u'suffix_3:in',\n",
       " u'prefix_3:in',\n",
       " u'suffix_2:in',\n",
       " u'word:production',\n",
       " u'prefix_3:pro',\n",
       " u'prefix_2:pr',\n",
       " u'prev_word:in',\n",
       " u'prev_word:production',\n",
       " u'next_word:exceptional',\n",
       " u'word:exceptional',\n",
       " u'next_word:quality',\n",
       " u'suffix_3:nal',\n",
       " u'prefix_3:exc',\n",
       " u'prefix_2:ex',\n",
       " u'word:quality',\n",
       " u'prefix_1:q',\n",
       " u'prefix_3:qua',\n",
       " u'prefix_2:qu',\n",
       " u'prev_word:exceptional',\n",
       " u'next_word:or',\n",
       " u'prev_word:quality',\n",
       " u'word:or',\n",
       " u'next_word:so',\n",
       " u'suffix_3:or',\n",
       " u'prefix_3:or',\n",
       " u'prefix_2:or',\n",
       " u'word:so',\n",
       " u'next_word:perceived',\n",
       " u'suffix_3:so',\n",
       " u'prefix_3:so',\n",
       " u'prefix_2:so',\n",
       " u'suffix_2:so',\n",
       " u'prev_word:or',\n",
       " u'word:perceived',\n",
       " u'suffix_3:ved',\n",
       " u'prefix_3:per',\n",
       " u'prefix_2:pe',\n",
       " u'prev_word:so',\n",
       " u'prev_word:perceived',\n",
       " u'next_word:at',\n",
       " u'word:at',\n",
       " u'next_word:any',\n",
       " u'suffix_3:at',\n",
       " u'prefix_3:at',\n",
       " u'prefix_2:at',\n",
       " u'word:any',\n",
       " u'next_word:rate',\n",
       " u'prefix_3:any',\n",
       " u'prev_word:at',\n",
       " u'word:rate',\n",
       " u'prefix_3:rat',\n",
       " u'prefix_2:ra',\n",
       " u'prev_word:any',\n",
       " u'prev_word:rate',\n",
       " u'next_word:with',\n",
       " u'word:with',\n",
       " u'next_word:exceedingly',\n",
       " u'suffix_3:ith',\n",
       " u'prefix_3:wit',\n",
       " u'suffix_2:th',\n",
       " u'suffix_1:h',\n",
       " u'word:exceedingly',\n",
       " u'next_word:high',\n",
       " u'suffix_3:gly',\n",
       " u'prev_word:with',\n",
       " u'word:high',\n",
       " u'next_word:prices',\n",
       " u'suffix_3:igh',\n",
       " u'prefix_3:hig',\n",
       " u'prefix_2:hi',\n",
       " u'suffix_2:gh',\n",
       " u'prev_word:exceedingly',\n",
       " u'word:prices',\n",
       " u'suffix_3:ces',\n",
       " u'prefix_3:pri',\n",
       " u'prev_word:high',\n",
       " u'prev_word:prices',\n",
       " u'word:As',\n",
       " u'suffix_3:As',\n",
       " u'prefix_3:As',\n",
       " u'prefix_2:As',\n",
       " u'suffix_2:As',\n",
       " u'next_word:private',\n",
       " u'prev_word:As',\n",
       " u'word:private',\n",
       " u'prev_word:private',\n",
       " u'next_word:Random',\n",
       " u'word:Random',\n",
       " u'next_word:House',\n",
       " u'suffix_3:dom',\n",
       " u'prefix_3:Ran',\n",
       " u'prefix_2:Ra',\n",
       " u'word:House',\n",
       " u'next_word:does',\n",
       " u'suffix_3:use',\n",
       " u'prefix_1:H',\n",
       " u'prefix_3:Hou',\n",
       " u'prefix_2:Ho',\n",
       " u'suffix_2:se',\n",
       " u'prev_word:Random',\n",
       " u'word:does',\n",
       " u\"next_word:n't\",\n",
       " u'suffix_3:oes',\n",
       " u'prefix_3:doe',\n",
       " u'prefix_2:do',\n",
       " u'prev_word:House',\n",
       " u\"word:n't\",\n",
       " u'next_word:report',\n",
       " u\"suffix_3:n't\",\n",
       " u'prefix_1:n',\n",
       " u\"prefix_3:n't\",\n",
       " u\"prefix_2:n'\",\n",
       " u\"suffix_2:'t\",\n",
       " u'prev_word:does',\n",
       " u'word:report',\n",
       " u'next_word:its',\n",
       " u'suffix_3:ort',\n",
       " u'prefix_3:rep',\n",
       " u'suffix_2:rt',\n",
       " u\"prev_word:n't\",\n",
       " u'word:its',\n",
       " u'next_word:earnings',\n",
       " u'suffix_3:its',\n",
       " u'prefix_3:its',\n",
       " u'prefix_2:it',\n",
       " u'prev_word:report',\n",
       " u'word:earnings',\n",
       " u'prev_word:its',\n",
       " u'prev_word:earnings',\n",
       " u'word:This',\n",
       " u'suffix_3:his',\n",
       " u'prefix_3:Thi',\n",
       " u'prev_word:This',\n",
       " u'next_word:0',\n",
       " u'word:0',\n",
       " u'suffix_3:0',\n",
       " u'prefix_1:0',\n",
       " u'prefix_3:0',\n",
       " u'prefix_2:0',\n",
       " u'suffix_2:0',\n",
       " u'suffix_1:0',\n",
       " u'next_word:negative',\n",
       " u'prev_word:0',\n",
       " u'word:negative',\n",
       " u'next_word:ad',\n",
       " u'suffix_3:ive',\n",
       " u'prefix_3:neg',\n",
       " u'prefix_2:ne',\n",
       " u'word:ad',\n",
       " u'suffix_3:ad',\n",
       " u'prefix_3:ad',\n",
       " u'suffix_2:ad',\n",
       " u'prev_word:negative',\n",
       " u'prev_word:ad',\n",
       " u'next_word:years',\n",
       " u'word:years',\n",
       " u'suffix_3:ars',\n",
       " u'next_word:secondary',\n",
       " u'prev_word:years',\n",
       " u'word:secondary',\n",
       " u'next_word:presence',\n",
       " u'suffix_3:ary',\n",
       " u'prefix_3:sec',\n",
       " u'word:presence',\n",
       " u'suffix_3:nce',\n",
       " u'prefix_3:pre',\n",
       " u'suffix_2:ce',\n",
       " u'prev_word:secondary',\n",
       " u'next_word:most',\n",
       " u'prev_word:presence',\n",
       " u'word:most',\n",
       " u'next_word:political',\n",
       " u'suffix_3:ost',\n",
       " u'prefix_3:mos',\n",
       " u'prefix_2:mo',\n",
       " u'word:political',\n",
       " u'next_word:campaigns',\n",
       " u'prefix_3:pol',\n",
       " u'prefix_2:po',\n",
       " u'prev_word:most',\n",
       " u'word:campaigns',\n",
       " u'suffix_3:gns',\n",
       " u'prefix_3:cam',\n",
       " u'prev_word:political',\n",
       " u'next_word:became',\n",
       " u'prev_word:campaigns',\n",
       " u'word:became',\n",
       " u'suffix_3:ame',\n",
       " u'prefix_3:bec',\n",
       " u'next_word:main',\n",
       " u'prev_word:became',\n",
       " u'word:main',\n",
       " u'next_word:event',\n",
       " u'suffix_3:ain',\n",
       " u'prefix_3:mai',\n",
       " u'word:event',\n",
       " u'suffix_3:ent',\n",
       " u'prefix_3:eve',\n",
       " u'prefix_2:ev',\n",
       " u'prev_word:main',\n",
       " u'prev_word:event',\n",
       " u'next_word:Having',\n",
       " u'word:Having',\n",
       " u'prefix_3:Hav',\n",
       " u'prefix_2:Ha',\n",
       " u'next_word:dividend',\n",
       " u'prev_word:Having',\n",
       " u'word:dividend',\n",
       " u'next_word:increases',\n",
       " u'suffix_3:end',\n",
       " u'prefix_3:div',\n",
       " u'word:increases',\n",
       " u'suffix_3:ses',\n",
       " u'prev_word:dividend',\n",
       " u'prev_word:increases',\n",
       " u'next_word:supportive',\n",
       " u'word:supportive',\n",
       " u'next_word:element',\n",
       " u'word:element',\n",
       " u'prefix_3:ele',\n",
       " u'prefix_2:el',\n",
       " u'prev_word:supportive',\n",
       " u'prev_word:element',\n",
       " u'next_word:outlook',\n",
       " u'word:outlook',\n",
       " u'suffix_3:ook',\n",
       " u'prefix_3:out',\n",
       " u'prefix_2:ou',\n",
       " u'suffix_2:ok',\n",
       " u'suffix_1:k',\n",
       " u'next_word:but',\n",
       " u'prev_word:outlook',\n",
       " u'word:but',\n",
       " u'next_word:I',\n",
       " u'suffix_3:but',\n",
       " u'prefix_3:but',\n",
       " u'prefix_2:bu',\n",
       " u'word:I',\n",
       " u'next_word:do',\n",
       " u'suffix_3:I',\n",
       " u'prefix_1:I',\n",
       " u'prefix_3:I',\n",
       " u'prefix_2:I',\n",
       " u'suffix_2:I',\n",
       " u'suffix_1:I',\n",
       " u'prev_word:but',\n",
       " u'word:do',\n",
       " u'suffix_3:do',\n",
       " u'prefix_3:do',\n",
       " u'suffix_2:do',\n",
       " u'prev_word:I',\n",
       " u'next_word:think',\n",
       " u'prev_word:do',\n",
       " u'word:think',\n",
       " u'suffix_3:ink',\n",
       " u'suffix_2:nk',\n",
       " u'next_word:it',\n",
       " u'prev_word:think',\n",
       " u'word:it',\n",
       " u\"next_word:'s\",\n",
       " u'suffix_3:it',\n",
       " u'prefix_3:it',\n",
       " u'suffix_2:it',\n",
       " u\"word:'s\",\n",
       " ...]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#len(model.state_features_)\n",
    "model.attributes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9554268148413771\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      -LRB-      1.000     1.000     1.000        30\n",
      "     -NONE-      1.000     1.000     1.000      1644\n",
      "      -RRB-      1.000     1.000     1.000        33\n",
      "         CC      0.995     0.997     0.996       590\n",
      "         CD      0.992     0.994     0.993       871\n",
      "         DT      0.994     0.989     0.992      2138\n",
      "         EX      0.852     1.000     0.920        23\n",
      "         FW      0.000     0.000     0.000         2\n",
      "         IN      0.967     0.982     0.975      2506\n",
      "         JJ      0.887     0.864     0.876      1564\n",
      "        JJR      0.837     0.854     0.845        96\n",
      "        JJS      1.000     0.843     0.915        51\n",
      "         LS      1.000     0.667     0.800         3\n",
      "         MD      1.000     0.987     0.994       234\n",
      "         NN      0.937     0.946     0.941      3403\n",
      "        NNP      0.949     0.987     0.968      2436\n",
      "       NNPS      0.744     0.525     0.615        61\n",
      "        NNS      0.953     0.980     0.966      1469\n",
      "        PDT      0.833     0.625     0.714         8\n",
      "        POS      0.977     1.000     0.989       216\n",
      "        PRP      0.998     0.986     0.992       427\n",
      "       PRP$      0.989     0.979     0.984       189\n",
      "         RB      0.915     0.871     0.892       676\n",
      "        RBR      0.789     0.441     0.566        34\n",
      "        RBS      1.000     1.000     1.000         4\n",
      "         RP      0.867     0.696     0.772        56\n",
      "        SYM      0.000     0.000     0.000         0\n",
      "         TO      0.996     0.998     0.997       532\n",
      "         UH      0.000     0.000     0.000         1\n",
      "         VB      0.951     0.921     0.935       629\n",
      "        VBD      0.941     0.959     0.950       788\n",
      "        VBG      0.902     0.946     0.923       370\n",
      "        VBN      0.921     0.884     0.902       543\n",
      "        VBP      0.900     0.838     0.868       321\n",
      "        VBZ      0.974     0.914     0.943       538\n",
      "        WDT      0.992     0.975     0.983       120\n",
      "         WP      0.985     1.000     0.992        64\n",
      "        WP$      1.000     1.000     1.000         5\n",
      "        WRB      1.000     0.872     0.932        47\n",
      "\n",
      "avg / total      0.956     0.956     0.955     22722\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "import string\n",
    "# conduct detailed evaluation\n",
    "\n",
    "labels = list(model.classes_)\n",
    "# remove symbol labels\n",
    "labels = [l for l in labels if len(l) >1 and l[1] in string.ascii_uppercase]\n",
    "print metrics.flat_f1_score(y_test, y_pred, average='weighted',labels=labels)\n",
    "\n",
    "# display per-class results\n",
    "print metrics.flat_classification_report(y_test, y_pred, labels=sorted(labels), digits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "MD     -> VB      4.944188\n",
      "TO     -> VB      3.035100\n",
      "JJ     -> NN      2.768665\n",
      "NNS    -> VBP     2.669795\n",
      "PRP    -> VBP     2.605842\n",
      "WDT    -> -NONE-  2.479925\n",
      "NNP    -> NNP     2.454811\n",
      "NNP    -> POS     2.420472\n",
      "JJ     -> NNS     2.356060\n",
      "CD     -> CD      2.333455\n",
      "PRP    -> VBD     2.326176\n",
      "PRP    -> VBZ     2.152002\n",
      "PRP$   -> NN      2.091057\n",
      "-NONE- -> VBP     2.073427\n",
      "VBN    -> -NONE-  2.049816\n",
      "$      -> CD      2.018674\n",
      "NNP    -> VBD     2.014314\n",
      "DT     -> NN      2.012249\n",
      "NN     -> POS     1.964675\n",
      "CD     -> NNS     1.962200\n"
     ]
    }
   ],
   "source": [
    "# check what classifier learned\n",
    "from collections import Counter\n",
    "def print_transitions(trans_features):\n",
    "    for (l_from, l_to), weight in trans_features:\n",
    "        print \"%-6s -> %-7s %0.6f\" % (l_from, l_to, weight)\n",
    "        \n",
    "print (\"Top likely transitions:\")\n",
    "print_transitions(Counter(model.transition_features_).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "6.151299 NNP      is_capitalised\n",
      "4.387084 -NONE-   prefix_1:*\n",
      "4.383760 VBZ      suffix_1:s\n",
      "4.369644 NNS      suffix_1:s\n",
      "4.342867 RB       suffix_2:ly\n",
      "3.938686 NN       is_all_lower\n",
      "3.738135 VBG      suffix_3:ing\n",
      "3.734816 VBN      suffix_2:ed\n",
      "3.538607 JJ       has_hypen\n",
      "3.377862 VBD      suffix_2:ed\n",
      "3.085612 CD       prefix_1:1\n",
      "3.010594 NNPS     suffix_1:s\n",
      "2.902327 JJ       suffix_3:ous\n",
      "2.744854 JJ       is_all_lower\n",
      "2.739277 JJ       word:many\n",
      "2.669771 VBD      suffix_1:d\n",
      "2.633840 NN       suffix_2:ss\n",
      "2.617963 VBN      suffix_1:d\n",
      "2.588813 JJR      suffix_2:er\n",
      "2.530668 DT       suffix_2:he\n",
      "2.497807 JJ       suffix_3:ble\n",
      "2.446247 RB       is_all_lower\n",
      "2.427643 VB       prev_word:n't\n",
      "2.403446 IN       prefix_3:tha\n",
      "2.400196 NNS      suffix_2:ts\n",
      "2.381873 JJ       suffix_2:al\n",
      "2.364360 JJS      suffix_2:st\n",
      "2.346303 CD       is_numeric\n",
      "2.337198 VBN      prev_word:has\n",
      "2.335452 VB       prev_word:*\n",
      "Top negative:\n",
      "-1.049359 JJ       suffix_3:eed\n",
      "-1.108168 NN       prev_word:are\n",
      "-1.110015 NNP      suffix_3:sed\n",
      "-1.110349 NN       prefix_3:mil\n",
      "-1.116982 NNS      suffix_2:0s\n",
      "-1.124831 VBG      is_capitalised\n",
      "-1.131729 NN       suffix_3:her\n",
      "-1.138915 NN       prev_word:be\n",
      "-1.152807 VBP      suffix_1:s\n",
      "-1.157773 NN       suffix_2:ly\n",
      "-1.165350 NNP      suffix_3:ian\n",
      "-1.175894 NN       prefix_2:th\n",
      "-1.176291 JJ       suffix_3:est\n",
      "-1.187930 NN       next_word:*U*\n",
      "-1.196438 VBN      next_word:0\n",
      "-1.226105 JJ       suffix_1:o\n",
      "-1.227233 NN       prev_word:been\n",
      "-1.240743 DT       prev_word:--\n",
      "-1.247532 JJ       suffix_1:s\n",
      "-1.262599 VBN      has_hypen\n",
      "-1.267026 VBD      has_hypen\n",
      "-1.277476 VBD      is_capitalised\n",
      "-1.327900 VBD      suffix_3:eed\n",
      "-1.346790 VBN      suffix_3:eed\n",
      "-1.354937 VB       suffix_1:s\n",
      "-1.546471 NNP      is_all_lower\n",
      "-1.651567 NNP      prev_word:*\n",
      "-1.884364 NN       suffix_2:ed\n",
      "-2.118251 NN       suffix_1:s\n",
      "-2.489029 NNPS     is_all_lower\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print \"%0.6f %-8s %s\" % (weight, label, attr)\n",
    "\n",
    "print (\"Top positive:\")\n",
    "print_state_features(Counter(model.state_features_).most_common(30))\n",
    "print (\"Top negative:\")\n",
    "print_state_features(Counter(model.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 2, 1]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
