{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result and observation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of learning rate, batch size, number of projections and normalisation of Dot Product lambda layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5 epochs; projections = 1; small learning rate\n",
    "\n",
    "('Epochs: ', 5, 'Batch size: ', 1, 'm: ', 10, 'pki_k: ', 1, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.0001, 'Bagging:', False)\n",
    "('Epoch:', 1, 'Loss:', 5434.059917956591, 'Test Loss:', 1.7142197, 'MRR:', 0.00222, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 2, 'Loss:', 3383.8066060245037, 'Test Loss:', 1.9515185, 'MRR:', 0.06841, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 3, 'Loss:', 3067.321956753731, 'Test Loss:', 1.7801317, 'MRR:', 0.06667, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 4, 'Loss:', 2886.389878883958, 'Test Loss:', 1.6223646, 'MRR:', 0.08452, 'Test accuracy:', 0.01)\n",
    "('Epoch:', 5, 'Loss:', 2724.6004183515906, 'Test Loss:', 1.4369333, 'MRR:', 0.12583, 'Test accuracy:', 0.06)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.16482\n",
    "MAP: 0.074\n",
    "P@1: 0.13009\n",
    "P@5: 0.06929\n",
    "P@10: 0.06626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increased learning rate; kept the rest of the parameters the same\n",
    "\n",
    "('Epochs: ', 5, 'Batch size: ', 1, 'm: ', 10, 'pki_k: ', 1, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.001, 'Bagging:', False, 'Normalised: ', True, 'max_or_combine: ', True)\n",
    "('Epoch:', 1, 'Loss:', 3087.841484054923, 'Test Loss:', 1.221919, 'MRR:', 0.0715, 'Test accuracy:', 0.34)\n",
    "('Epoch:', 2, 'Loss:', 2054.3461547754705, 'Test Loss:', 1.0705938, 'MRR:', 0.07336, 'Test accuracy:', 0.545)\n",
    "('Epoch:', 3, 'Loss:', 1771.3332415279, 'Test Loss:', 1.1465548, 'MRR:', 0.10686, 'Test accuracy:', 0.59)\n",
    "('Epoch:', 4, 'Loss:', 1666.5093106641434, 'Test Loss:', 1.2143168, 'MRR:', 0.09489, 'Test accuracy:', 0.6)\n",
    "('Epoch:', 5, 'Loss:', 1626.3074470881838, 'Test Loss:', 1.1445898, 'MRR:', 0.10333, 'Test accuracy:', 0.615)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.10766\n",
    "MAP: 0.04885\n",
    "P@1: 0.07405\n",
    "P@5: 0.04708\n",
    "P@10: 0.04511\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unnormalised dot product jacks up accuracy but MRR decreases\n",
    "\n",
    "('Epochs: ', 5, 'Batch size: ', 1, 'm: ', 10, 'pki_k: ', 1, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.0001, 'Bagging:', False, 'Normalised: ', False)\n",
    "('Epoch:', 1, 'Loss:', 4453.945554658771, 'Test Loss:', 2.1793892, 'MRR:', 0.0, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 2, 'Loss:', 3145.656360551715, 'Test Loss:', 1.9592289, 'MRR:', 0.00952, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 3, 'Loss:', 2865.1507012546062, 'Test Loss:', 1.7924066, 'MRR:', 0.04, 'Test accuracy:', 0.06)\n",
    "('Epoch:', 4, 'Loss:', 2669.642120765522, 'Test Loss:', 1.6634755, 'MRR:', 0.05667, 'Test accuracy:', 0.15)\n",
    "('Epoch:', 5, 'Loss:', 2545.2243698434904, 'Test Loss:', 1.5633432, 'MRR:', 0.07333, 'Test accuracy:', 0.2)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.11047\n",
    "MAP: 0.04882\n",
    "P@1: 0.08005\n",
    "P@5: 0.04651\n",
    "P@10: 0.04418"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increased epochs to 10\n",
    "* Performance did not increase; in fact it slightly decreased\n",
    "\n",
    "('Epochs: ', 10, 'Batch size: ', 1, 'm: ', 10, 'pki_k: ', 1, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.0001, 'Bagging:', False, 'Normalised: ', True)\n",
    "('Epoch:', 1, 'Loss:', 5362.2906921207905, 'Test Loss:', 1.7285297, 'MRR:', 0.00333, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 2, 'Loss:', 3365.5553729087114, 'Test Loss:', 1.9494666, 'MRR:', 0.079, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 3, 'Loss:', 3050.8074078708887, 'Test Loss:', 1.7437555, 'MRR:', 0.089, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 4, 'Loss:', 2874.3782879412174, 'Test Loss:', 1.5833812, 'MRR:', 0.12067, 'Test accuracy:', 0.015)\n",
    "('Epoch:', 5, 'Loss:', 2714.08142259717, 'Test Loss:', 1.4525275, 'MRR:', 0.09886, 'Test accuracy:', 0.065)\n",
    "('Epoch:', 6, 'Loss:', 2569.657343737781, 'Test Loss:', 1.4007355, 'MRR:', 0.09971, 'Test accuracy:', 0.175)\n",
    "('Epoch:', 7, 'Loss:', 2443.604718454182, 'Test Loss:', 1.2846951, 'MRR:', 0.10983, 'Test accuracy:', 0.265)\n",
    "('Epoch:', 8, 'Loss:', 2321.1428721919656, 'Test Loss:', 1.2566333, 'MRR:', 0.08986, 'Test accuracy:', 0.3)\n",
    "('Epoch:', 9, 'Loss:', 2227.240024898201, 'Test Loss:', 1.2069659, 'MRR:', 0.13233, 'Test accuracy:', 0.33)\n",
    "('Epoch:', 10, 'Loss:', 2133.6892498247325, 'Test Loss:', 1.1765708, 'MRR:', 0.12872, 'Test accuracy:', 0.395)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.16253\n",
    "MAP: 0.07592\n",
    "P@1: 0.12408\n",
    "P@5: 0.07299\n",
    "P@10: 0.06819\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increasing phi k to 5, performance decreases substantially\n",
    "\n",
    "('Epochs: ', 5, 'Batch size: ', 1, 'm: ', 10, 'pki_k: ', 5, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.0001, 'Bagging:', False, 'Normalised: ', True)\n",
    "('Epoch:', 1, 'Loss:', 5599.581994116306, 'Test Loss:', 1.7155834, 'MRR:', 0.0, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 2, 'Loss:', 3420.1822370290756, 'Test Loss:', 2.295699, 'MRR:', 0.00833, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 3, 'Loss:', 3200.9527019411325, 'Test Loss:', 2.2430234, 'MRR:', 0.005, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 4, 'Loss:', 3061.4911769777536, 'Test Loss:', 2.2100976, 'MRR:', 0.005, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 5, 'Loss:', 2932.8777290284634, 'Test Loss:', 2.1711895, 'MRR:', 0.004, 'Test accuracy:', 0.0)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.02504\n",
    "MAP: 0.01376\n",
    "P@1: 0.006\n",
    "P@5: 0.01525\n",
    "P@10: 0.0146"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this model, the similarities yielded by each projection matrix are combined.\n",
    "\n",
    "('Epochs: ', 5, 'Batch size: ', 1, 'm: ', 10, 'pki_k: ', 5, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.0001, 'Bagging:', False, 'Normalised: ', True, 'max_or_combine: ', False)\n",
    "('Epoch:', 1, 'Loss:', 2444.765578765422, 'Test Loss:', 1.2538909, 'MRR:', 0.11867, 'Test accuracy:', 0.34)\n",
    "('Epoch:', 2, 'Loss:', 1961.9933971371502, 'Test Loss:', 1.065004, 'MRR:', 0.11267, 'Test accuracy:', 0.47)\n",
    "('Epoch:', 3, 'Loss:', 1692.451527159661, 'Test Loss:', 0.9963348, 'MRR:', 0.11186, 'Test accuracy:', 0.605)\n",
    "('Epoch:', 4, 'Loss:', 1521.266854035668, 'Test Loss:', 1.0086627, 'MRR:', 0.09183, 'Test accuracy:', 0.6)\n",
    "('Epoch:', 5, 'Loss:', 1411.3310520895757, 'Test Loss:', 0.9977115, 'MRR:', 0.11371, 'Test accuracy:', 0.635)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.13219\n",
    "MAP: 0.0602\n",
    "P@1: 0.09473\n",
    "P@5: 0.05755\n",
    "P@10: 0.05501\n",
    "\n",
    "\n",
    "* Accuracy increases, although MRR decreased a bit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increased batch_size, decreased learning rate.  Training on k = 5 and combined similarities\n",
    "\n",
    "('Epochs: ', 5, 'Batch size: ', 32, 'm: ', 10, 'pki_k: ', 5, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.001, 'Bagging:', False, 'Normalised: ', True, 'max_or_combine: ', False)\n",
    "('Epoch:', 1, 'Loss:', 186.0187285244465, 'Test Loss:', 1.3526733, 'MRR:', 0.0, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 2, 'Loss:', 121.69307062029839, 'Test Loss:', 1.6924609, 'MRR:', 0.03583, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 3, 'Loss:', 94.27977474033833, 'Test Loss:', 1.5296357, 'MRR:', 0.06667, 'Test accuracy:', 0.05)\n",
    "('Epoch:', 4, 'Loss:', 79.67942371964455, 'Test Loss:', 1.2733743, 'MRR:', 0.09468, 'Test accuracy:', 0.27)\n",
    "('Epoch:', 5, 'Loss:', 70.00693801045418, 'Test Loss:', 1.0368507, 'MRR:', 0.11333, 'Test accuracy:', 0.44)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.1723\n",
    "MAP: 0.07943\n",
    "P@1: 0.13542\n",
    "P@5: 0.07536\n",
    "P@10: 0.07143\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increased epochs; \n",
    "\n",
    "('Epochs: ', 10, 'Batch size: ', 32, 'm: ', 10, 'pki_k: ', 5, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.001, 'Bagging:', False, 'Normalised: ', True, 'max_or_combine: ', False)\n",
    "('Epoch:', 1, 'Loss:', 194.8300702571869, 'Test Loss:', 1.2967992, 'MRR:', 0.0, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 2, 'Loss:', 125.49962946772575, 'Test Loss:', 1.6891345, 'MRR:', 0.01667, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 3, 'Loss:', 95.76934903860092, 'Test Loss:', 1.5457877, 'MRR:', 0.06917, 'Test accuracy:', 0.06)\n",
    "('Epoch:', 4, 'Loss:', 80.44232292473316, 'Test Loss:', 1.2914896, 'MRR:', 0.10667, 'Test accuracy:', 0.25)\n",
    "('Epoch:', 5, 'Loss:', 70.48138792812824, 'Test Loss:', 1.0320518, 'MRR:', 0.1, 'Test accuracy:', 0.43)\n",
    "('Epoch:', 6, 'Loss:', 63.13052502274513, 'Test Loss:', 0.8962378, 'MRR:', 0.1015, 'Test accuracy:', 0.57)\n",
    "('Epoch:', 7, 'Loss:', 57.48013845831156, 'Test Loss:', 0.7704553, 'MRR:', 0.09786, 'Test accuracy:', 0.665)\n",
    "('Epoch:', 8, 'Loss:', 53.15286573022604, 'Test Loss:', 0.74941653, 'MRR:', 0.12, 'Test accuracy:', 0.68)\n",
    "('Epoch:', 9, 'Loss:', 49.19772472977638, 'Test Loss:', 0.69557023, 'MRR:', 0.135, 'Test accuracy:', 0.71)\n",
    "('Epoch:', 10, 'Loss:', 46.39858826249838, 'Test Loss:', 0.68561304, 'MRR:', 0.11567, 'Test accuracy:', 0.715)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.15738\n",
    "MAP: 0.07452\n",
    "P@1: 0.11408\n",
    "P@5: 0.07121\n",
    "P@10: 0.06825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* set epochs to 8 and performance is better, but seems the more epochs the model is trained for, the better accuracy becomes but the ability to derive hypernym reduces\n",
    "\n",
    "('Epochs: ', 8, 'Batch size: ', 32, 'm: ', 10, 'pki_k: ', 5, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.001, 'Bagging:', False, 'Normalised: ', True, 'max_or_combine: ', False)\n",
    "('Epoch:', 1, 'Loss:', 204.11419826745987, 'Test Loss:', 1.2493482, 'MRR:', 0.0, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 2, 'Loss:', 129.49780678749084, 'Test Loss:', 1.6709774, 'MRR:', 0.02333, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 3, 'Loss:', 97.2472752481699, 'Test Loss:', 1.5687093, 'MRR:', 0.04333, 'Test accuracy:', 0.06)\n",
    "('Epoch:', 4, 'Loss:', 80.94737029075623, 'Test Loss:', 1.3242977, 'MRR:', 0.10286, 'Test accuracy:', 0.24)\n",
    "('Epoch:', 5, 'Loss:', 70.73110197484493, 'Test Loss:', 1.0752355, 'MRR:', 0.10133, 'Test accuracy:', 0.405)\n",
    "('Epoch:', 6, 'Loss:', 63.182005539536476, 'Test Loss:', 0.8862095, 'MRR:', 0.09852, 'Test accuracy:', 0.56)\n",
    "('Epoch:', 7, 'Loss:', 57.57530136406422, 'Test Loss:', 0.76840204, 'MRR:', 0.11083, 'Test accuracy:', 0.655)\n",
    "('Epoch:', 8, 'Loss:', 53.23740182071924, 'Test Loss:', 0.70503455, 'MRR:', 0.12417, 'Test accuracy:', 0.7)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.16145\n",
    "MAP: 0.07436\n",
    "P@1: 0.12742\n",
    "P@5: 0.07049\n",
    "P@10: 0.06696\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Replaced similarity combination for maximum similarity.  Accuracy reduces and MRR is more \"noisy\", increaseing and descreasing as epochs elapse.\n",
    "\n",
    "('Epochs: ', 8, 'Batch size: ', 32, 'm: ', 10, 'pki_k: ', 5, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.001, 'Bagging:', False, 'Normalised: ', True, 'max_or_combine: ', True)\n",
    "('Epoch:', 1, 'Loss:', 168.36146503686905, 'Test Loss:', 1.2841839, 'MRR:', 0.0, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 2, 'Loss:', 132.75384551286697, 'Test Loss:', 1.6081719, 'MRR:', 0.01, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 3, 'Loss:', 112.59316456317902, 'Test Loss:', 1.866642, 'MRR:', 0.019, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 4, 'Loss:', 102.50527966022491, 'Test Loss:', 1.9889398, 'MRR:', 0.10167, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 5, 'Loss:', 97.91911605000496, 'Test Loss:', 1.9175035, 'MRR:', 0.0825, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 6, 'Loss:', 95.19544239342213, 'Test Loss:', 1.8228943, 'MRR:', 0.11583, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 7, 'Loss:', 92.6340853124857, 'Test Loss:', 1.7497772, 'MRR:', 0.06633, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 8, 'Loss:', 90.27319814264774, 'Test Loss:', 1.6723123, 'MRR:', 0.045, 'Test accuracy:', 0.0)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.16227\n",
    "MAP: 0.07431\n",
    "P@1: 0.12875\n",
    "P@5: 0.07114\n",
    "P@10: 0.06624\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The simplest model seems to work the best would fare poorly as a classifier.  Test loss becomes unreliable as an indicator of convergence.  \n",
    "\n",
    "('Epochs: ', 10, 'Batch size: ', 32, 'm: ', 10, 'pki_k: ', 1, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.001, 'Bagging:', False, 'Normalised: ', True, 'max_or_combine: ', True)\n",
    "('Epoch:', 1, 'Loss:', 211.29751026630402, 'Test Loss:', 1.026911, 'MRR:', 0.0, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 2, 'Loss:', 163.02259212732315, 'Test Loss:', 1.3421971, 'MRR:', 0.0, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 3, 'Loss:', 131.97357830405235, 'Test Loss:', 1.6452805, 'MRR:', 0.01067, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 4, 'Loss:', 113.95281785726547, 'Test Loss:', 1.8410842, 'MRR:', 0.05233, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 5, 'Loss:', 104.24142009019852, 'Test Loss:', 1.8910432, 'MRR:', 0.10333, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 6, 'Loss:', 99.29711124300957, 'Test Loss:', 1.8424951, 'MRR:', 0.10333, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 7, 'Loss:', 96.59657937288284, 'Test Loss:', 1.7573483, 'MRR:', 0.09352, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 8, 'Loss:', 94.29305498301983, 'Test Loss:', 1.683889, 'MRR:', 0.14067, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 9, 'Loss:', 92.09379416704178, 'Test Loss:', 1.6090918, 'MRR:', 0.12067, 'Test accuracy:', 0.0)\n",
    "('Epoch:', 10, 'Loss:', 89.94298177957535, 'Test Loss:', 1.526624, 'MRR:', 0.11467, 'Test accuracy:', 0.0)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.17784\n",
    "MAP: 0.08239\n",
    "P@1: 0.14143\n",
    "P@5: 0.0785\n",
    "P@10: 0.07372\n",
    "\n",
    "* 315 (from 1500 examples), roughly 20% feature the query term as a result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding the number of k projections, reduces the performance of the model.\n",
    "\n",
    "('Epochs: ', 5, 'Batch size: ', 32, 'm: ', 10, 'pki_k: ', 20, 'train_embeddings: ', False, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'Dropout rate: ', 0.3, 'Kernel constraint: ', 'None', 'Learning rate: ', 0.001, 'Bagging:', False, 'Normalised: ', True, 'max_or_combine: ', False)\n",
    "('Epoch:', 1, 'Loss:', 70.67202708125114, 'Test Loss:', 1.1669564, 'MRR:', 0.05222, 'Test accuracy:', 0.455)\n",
    "('Epoch:', 2, 'Loss:', 51.84315085411072, 'Test Loss:', 0.9394446, 'MRR:', 0.074, 'Test accuracy:', 0.645)\n",
    "('Epoch:', 3, 'Loss:', 42.63686107844114, 'Test Loss:', 0.8948852, 'MRR:', 0.10952, 'Test accuracy:', 0.69)\n",
    "('Epoch:', 4, 'Loss:', 37.811192993074656, 'Test Loss:', 0.8913281, 'MRR:', 0.09233, 'Test accuracy:', 0.715)\n",
    "('Epoch:', 5, 'Loss:', 34.811650689691305, 'Test Loss:', 0.98019254, 'MRR:', 0.08667, 'Test accuracy:', 0.725)\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.10704\n",
    "MAP: 0.04943\n",
    "P@1: 0.07205\n",
    "P@5: 0.04805\n",
    "P@10: 0.04625\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reduce negative samples to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustered Yamane/CRIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In general, Yamane's idea of soft-clustering does not work well wit the Shared Task data. \n",
    "* This technique involves training CRIM-style, but on one sample at a time.  Each sample prediction is taken\n",
    "* If a set number of epochs have elapsed, examples less than a particular threshold are thrown out\n",
    "* A lot of data is wasted and a relatively narrow number of hypernyms are learnt\n",
    "* However, it still fares a bit better than MFH\n",
    "* Strangely with increasing epochs ability to classify hypernymy relationship is reduced\n",
    "\n",
    "\n",
    "Training started at: 2018-12-28 16:25:17.060095\n",
    "('m: ', 10, 'lambda: ', 0.15, 'max epoch per cluster: ', 5, 'Negative sampling: ', 'random', 'Phi Init: ', 'random_identity', 'sigmoid_kernel_constraint: ', 'ForceToOne', 'dropout: ', 0.2, 'learning_rate: ', 0.0001, 'cluster_max: ', 1)\n",
    "('Sample clusters size: ', 11779)\n",
    "('Processed ', 1000, 'samples...')\n",
    "('Processed ', 2000, 'samples...')\n",
    "('Processed ', 3000, 'samples...')\n",
    "('Processed ', 4000, 'samples...')\n",
    "('Processed ', 5000, 'samples...')\n",
    "('Processed ', 6000, 'samples...')\n",
    "('Processed ', 7000, 'samples...')\n",
    "('Processed ', 8000, 'samples...')\n",
    "('Processed ', 9000, 'samples...')\n",
    "('Processed ', 10000, 'samples...')\n",
    "('Processed ', 11000, 'samples...')\n",
    "Running evaluation on trial data set...\n",
    "('Epoch:', 1, 'Cluster #:', 1, 'Loss:', 0.4274288941491327, 'Test MRR:', 0.00222)\n",
    "('Processed ', 1000, 'samples...')\n",
    "('Processed ', 2000, 'samples...')\n",
    "('Processed ', 3000, 'samples...')\n",
    "('Processed ', 4000, 'samples...')\n",
    "('Processed ', 5000, 'samples...')\n",
    "('Processed ', 6000, 'samples...')\n",
    "('Processed ', 7000, 'samples...')\n",
    "('Processed ', 8000, 'samples...')\n",
    "('Processed ', 9000, 'samples...')\n",
    "('Processed ', 10000, 'samples...')\n",
    "('Processed ', 11000, 'samples...')\n",
    "Running evaluation on trial data set...\n",
    "('Epoch:', 2, 'Cluster #:', 1, 'Loss:', 0.30025950589332867, 'Test MRR:', 0.10333)\n",
    "('Processed ', 1000, 'samples...')\n",
    "('Processed ', 2000, 'samples...')\n",
    "('Processed ', 3000, 'samples...')\n",
    "('Processed ', 4000, 'samples...')\n",
    "('Processed ', 5000, 'samples...')\n",
    "('Processed ', 6000, 'samples...')\n",
    "('Processed ', 7000, 'samples...')\n",
    "('Processed ', 8000, 'samples...')\n",
    "('Processed ', 9000, 'samples...')\n",
    "('Processed ', 10000, 'samples...')\n",
    "('Processed ', 11000, 'samples...')\n",
    "Running evaluation on trial data set...\n",
    "('Epoch:', 3, 'Cluster #:', 1, 'Loss:', 0.27101560784188505, 'Test MRR:', 0.18582)\n",
    "('Processed ', 1000, 'samples...')\n",
    "('Processed ', 2000, 'samples...')\n",
    "('Processed ', 3000, 'samples...')\n",
    "('Processed ', 4000, 'samples...')\n",
    "('Processed ', 5000, 'samples...')\n",
    "('Processed ', 6000, 'samples...')\n",
    "('Processed ', 7000, 'samples...')\n",
    "('Processed ', 8000, 'samples...')\n",
    "('Processed ', 9000, 'samples...')\n",
    "('Processed ', 10000, 'samples...')\n",
    "('Processed ', 11000, 'samples...')\n",
    "Running evaluation on trial data set...\n",
    "('Epoch:', 4, 'Cluster #:', 1, 'Loss:', 0.26220812599193183, 'Test MRR:', 0.165)\n",
    "('Processed ', 1000, 'samples...')\n",
    "('Processed ', 2000, 'samples...')\n",
    "('Processed ', 3000, 'samples...')\n",
    "('Processed ', 4000, 'samples...')\n",
    "('Processed ', 5000, 'samples...')\n",
    "('Processed ', 6000, 'samples...')\n",
    "('Processed ', 7000, 'samples...')\n",
    "('Processed ', 8000, 'samples...')\n",
    "('Processed ', 9000, 'samples...')\n",
    "('Processed ', 10000, 'samples...')\n",
    "('Processed ', 11000, 'samples...')\n",
    "Running evaluation on trial data set...\n",
    "('Epoch:', 5, 'Cluster #:', 1, 'Loss:', 0.2575773902333948, 'Test MRR:', 0.17167)\n",
    "Training concluded at: 2018-12-28 16:29:33.554724\n",
    "\n",
    "\n",
    "Generating predictions...\n",
    "('Done', 100)\n",
    "('Done', 200)\n",
    "('Done', 300)\n",
    "('Done', 400)\n",
    "('Done', 500)\n",
    "('Done', 600)\n",
    "('Done', 700)\n",
    "('Done', 800)\n",
    "('Done', 900)\n",
    "('Done', 1000)\n",
    "('Done', 1100)\n",
    "('Done', 1200)\n",
    "('Done', 1300)\n",
    "('Done', 1400)\n",
    "CRIM evaluation:\n",
    "MRR: 0.25363\n",
    "MAP: 0.10591\n",
    "P@1: 0.23482\n",
    "P@5: 0.09525\n",
    "P@10: 0.08999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
